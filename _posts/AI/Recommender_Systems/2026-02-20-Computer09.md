---
title: "[Paper Review] Matrix Factorization Techniques for Recommender Systems"
categories: [Activities, Recommender Systems]
tags:
  - AI
  - Recommender Systems
layout: single
toc : true
toc_sticky: true
comments: true
use_math: true
---

**Matrix Factorization Techniques for Recommender Systems**  
(Yehuda Koren, Robert Bell, Chris Volinsky, IEEE Computer, 2009)
{: .notice--info}

## 0. 이 논문에 대하여..
본 논문은 PrecS Lab에서 두 번째로 읽게 된 논문입니다. <br>
NN (Nearest Neighbor) 방법보다 우수하다는 행렬 분해 모델을 소개하는 논문이었으며, 해당 모델은 Netflix Prize 대회에서 입증되었듯이 Implicit feedback, temporal effects, confidence levels와 같은 추가적인 정보를 모델에 포함시킬 수 있게 해주는 모델입니다. <br> <br> <br>

## 1. 서론
오늘날 소비자들에게는 수많은 선택지가 주어집니다. <br>
온라인 쇼핑몰이나 OTT 등과 같은 서비스들은 엄청 다양한 상품들을 제공하고 있어서, 각 사용자의 취향이나 니즈를 만족시키는, <span style="color: blue">**딱 맞는 상품을 사용자와 연결시켜주는 것**</span>이 사용자 만족도와 충성도를 높이는 데 매우 중요해졌습니다. <br> <br>
이런 이유로 아마존이나 넷플릭스 같은 많은 기업들이 추천시스템에 관심을 가지게 되었는데, 추천시스템이란 사용자가 어떤 상품에 관심을 보이는지 패턴을 분석해서 취향에 맞는 더 <span style="color: blue">개인화된 추천</span>을 제공하는 기술입니다. <br> (제가 소속되어 있는 PrecS 랩도 **Personalized** Recommender System 의 약자입니다.) <br>
특히 이런 추천 시스템은 영화, 음악, TV 쇼 같은 엔터테인먼트 콘텐츠에서 더 유용하다고 합니다. <br> <br>
더욱이 영화 같은 경우에는 여러 사람이 같은 영화를 보기도 하고, 한 사람이 여러 영화를 보기도 하며 사용자들은 영화에 대한 만족도를 직접 평가(rating)하기 때문에 영화가 누구에게 잘 맞는지에 대한 데이터가 엄청 많이 쌓일 수 있습니다. 기업들이 이렇게 많이 쌓인 데이터를 분석해서 각 사용자에게 볼 만한 영화를 추천해줄 수 있게 됩니다. <br> <br>

## 2. Recommender System Strategies
(바로 전에 읽은 논문 내용을 간추려서 담은 문단)
크게 보면 추천시스템은 CB와 CF 방법이 있습니다. <br>

### 🐾 CB (Content Based) 방법 <br>
각 사용자나 각 상품의 특성을 설명하는 <span style="color: blue">profile</span>을 만듭니다. <br>
예를들어 영화 같은 경우, 장르, 출연 배우, 흥행 정도 등의 정보가 영화 프로필(이전 논문에서의 표현 : item profile)에 포함될 수 있습니다. <br>
이러한 프로필을 이용해 추천시스템은 사용자와 잘 맞는 상품을 연결해줍니다. <br>
물론, CB 방식은 외부 정보를 수집해야하는데, 이 정보가 항상 수집하기 쉬운 것은 아니기 때문에 어려움이 있습니다. <br>
CB의 대표적인 성공 사례로는 <span style="color: blue"> Music Genome Project </span>이 있습니다. <br>

음악 게놈 프로젝트가 무엇인지: <https://en.wikipedia.org/wiki/Music_Genome_Project>

이는 인터넷 라디오 서비스 pandora.com에서 사용되는 기술이라고 합니다. <br>
이 프로젝트에서는 음악 분석가가 수백가지 음악적 특성을 기준으로 각 곡을 평가하고, 이러한 속성들(Genome, 유전자?라고 표현?)은 단순히 곡의 음악적 특징 뿐만 아니라 듣는이의 음악적인 선호도까지 반영합니다. <br> <br>

### 🐾 CF(Collaborative Filtering) 방법 <br>
CF 방법은 과거 사용자의 행동 (rating이나 구매이력.. 등)만을 이용하고 explicit profile은 만들지 않는 방법입니다. <br>
CF는 최초의 추천 시스템인 Tapestry의 개발자들이 만든 말이라고 합니다.
<br> <br> CF는 사용자들 사이의 관계와 상품들 사이의 관련성을 분석해서 새로운 사용자-아이템 연결을 찾아냅니다. <br>
CF의 가장 큰 장점은 <span style="background-color: #fff3cd">특정 분야에 종속되지 않는 domain free방식이라는 점</span> 과, <span style="background-color: #fff3cd">CB 방법만으로는 파악하기 어려운 데이터 특성도 다룰 수 있다는 점</span> 입니다. <br>
일반적으로는 CB보다 CF가 더 정확하지만, 새로운 사용자나 새로운 상품에 대해서는 추천이 어려운 
cold start problem이 존재하는 방법이기에 어떤 경우에서는 CB가 더 유용합니다. <br>

또, CF는 다시 **이웃 기반 방법(neighborhood methods)**과 **잠재 요인 모델(latent factor models)**로 나뉩니다. <br>

#### 이웃 기반 방법 (neighborhood methods)
이 방법은 다시 Item-based와 User-based로 나뉩니다. <br>
**Item based**는 사용자가 좋은 평점을 매긴 영화와 "비슷한 영화끼리" 묶어서 추천하는 방식이고, <br> **User based**는 취향이 사용자와 비슷한 사람들을 찾아서 추천하는 방식입니다. <br>
예를들어 어떤 사용자가 라이언 일병 구하기라는 영화를 아직 보지 않았다고 하겠습니다. <br>
시스템은 먼저 해당 영화와 비슷한 영화를 찾을 건데, 이때 비슷하다는 것은 같은 사람들이 비슷한 점수를 준 영화들을 의미합니다. <br> 
<u>여기서 같다란?</u> <br>
CF는 CB와 달리 인구 통계 정보를 쓰지 않습니다. 그래서 같다는것이 뭐 같은 여성인 사용자, 같은 나잇대의 사용자... 이런게 아니라 해리포터를 똑같이 좋아한 사람, 아니면 인터스텔라를 싫어한 사람.. 뭐 이런 느낌으로 이해하세용 <br>
라이언 일병 구하기 같은 경우 전쟁영화, 스필버그 감독의 영화, 톰행크스가 출연한 영화 등이 이웃 영화(=비슷한 영화)로 뽑힐 것입니다. <br> 이제 그 사용자가 이미 본 영화들 중에서 이 이웃 영화들 평점을 확인합니다. <br>
무슨 말이냐면, 만약 그 사용자가 전쟁 영화들을 모두 높게 평가했다면? -> 라이언 일병 구하기도 높게 평가할 확률이 높다! <br>

반면에 **user oriented** 방식은 아래 그림과 함께 설명하겠습니다. 

![Computer09](/assets/images/computer05_figure1.png) 

나랑 취향이 비슷한 사람들을 찾아서, 그 사람들이 좋아한 영화를 추천하는 것이 user oriented 방식입니다. <br> 

그림에서는 joe가 왼쪽의 3개 영화를 좋아하고, 시스템은 **joe와 같은 영화들을 좋아한 다른 사람들을 찾습니다.** 그 후 그 사람들이 공통으로 좋아한 영화가 무엇인지를 확인합니다. <br> 그 결과 그 사람들이 전부 좋아한 라이언 일병 구하기는 1순위로, 듄은 2순위로 추천이 될 것입니다. <br> 저도 듄 보고싶습니다. 블로깅 마치면 백준 풀고 듄 보다 잘 것입니다. 히히
<br> <br>

#### 잠재 요인 모델(latent factor models)
또 다른 방법인 <span style="color: blue">잠재 요인 모델(latent factor model)</span>은 <span style="background-color: #fff3cd">평점 패턴으로부터 추론된 약 20~100개의 요인들을 이용해 사용자와 아이템을 동시에 설명하려고 하는 방법</span>입니다. <br> 이러한 요인들은 코미디, 드라마, 액션, 아동 대상 여부 같은 명확한 특성일 수도 있지만 캐릭터의 깊이감이나 독특함 같은 모호한 특성일 수도 있습니다. 각 사용자에 대해, 각 요인은 해당 특성이 강한 영화를 얼마나 좋아하는지를 나타냅니다. <br> 
예를 들어 2개의 차원을 "여성 취향 - 남성 취향" 과 "진지함 - 코미디"로 가정한 그림은 다음과 같습니다. 

![Computer09](/assets/images/computer05_figure1.png) 

male versus female 축과 serious versus escapist 축으로 이루어진 평면 위에 몇몇 영화와 가상의 사용자들이 배치되어있는 그림입니다. <br> 
이 모델에서는 어떤 사용자의 영화 예상 rating이 (영화 평균 평점 대비) 사용자 위치 벡터와 영화 위치 벡터의 **내적**으로 계산됩니다. <br> 예를 들어 Gus는 Dumb and Dumber를 매우 좋아하고, The Color Purple은 싫어하며, Braveheart는 평균 정도로 평가할 것으로 예상됩니다. 또한 Ocean’s 11 같은 영화나 Dave 같은 사용자는 이 두 차원에서 비교적 중간에 위치한 것을 확인할 수 있습니다. 

위 내용을 정리하면 아래와 같습니다. 
(제가 발표용으로 만든 피피티 중 일부입니다.)

![Computer09](/assets/images/02ppt1.png)

## 3. Matrix Factorization Methods
Latent Factor Model의 가장 성공적인 구현 방식 중 하나는 **행렬분해 (matrix factorization)**입니다. <br>
행렬 분해는 item rating 패턴으로부터 추론된 factor vector(요인 벡터)를 이용해 사용자와 아이템을 동시에 표현한다고 합니다. <br>
그리고 사용자 요인과 아이템 요인이 유사할수록 해당 아이템이 해당 사용자에게 추천된다고 합니다. <br>
이러한 방법은 좋은 확장성(scalability)과 높은 예측 정확도, 다양한 실제 상황을 모델링할 수 있는 높은 유연성이라는 장점을 가지고 있다고 합니다. 따라서 (논문기준) 최근 들어 널리 사용되고 있다고 합니다. <br> <br>
<span style="background-color: #fff3cd">추천 시스템은 다양한 형태의 입력 데이터를 사용하는데, 보통 한 축은 사용자, 다른 한 축은 아이템을 나타내는 행렬 형태</span>로 표현됩니다. <br>
가장 다루기 쉬운 데이터는 사용자가 자신의 선호를 직접 표현한 <span style="background-color: #fff3cd">explicit feedback 데이터(rating)</span> 입니다. <br> 예를 들어 Netflix는 영화에 대한 rating을 수집하고, TiVo 사용자는 TV 프로그램에 대해 ‘좋아요/싫어요’ 버튼을 눌러 선호를 표시합니다. 이런 명시적인 피드백 (explicit feedback)을 이전 논문에서는 rating이라고 표현했습니다. 이런 explicit feedback 행렬은 <span style="background-color: #fff3cd">sparsity</span> 문제가 존재합니다. <br>
<span style="color: red">행렬 분해의 장점 중 하나는 explicit feedback 행렬이 희소 행렬인 경우 추가적인 정보(implicit feedback)도 함께 이용해서 추천할 수 있다는 점입니다. </span> <br>
구매 이력, 검색 기록, 마우스 움직임 등과 같은 사용자 행동을 관찰해서 간접적으로 선호를 파악하는 방식이 implicit feedback(암묵적 피드백)입니다. <br> 이는 보통 <span style="background-color: #fff3cd">어떤 행동의 발생 여부(있음/없음)</span>를 나타내기 때문에 보다 더 dense matrix로 표현됩니다. 

## 4. A Basic Matrix Factorization Model
행렬 분해 모델은 user 와 item을 공통된 잠재 요인 공간(latent factor space, 차원 수 f)으로 매핑하고, 그 공간에서 **내적**을 통해 item-user의 관계를 모델링합니다. <br>
즉 각 아이템 i는 $q_i \in \mathbb{R}^f$ 로, 각 사용자 u는 $p_u \in \mathbb{R}^f$ 로 표현됩니다. <br>

- 특정 아이템 i에 대해 $q_i$ 의 각 원소 : 그 아이템이 해당 factor를 얼마나 많이 가지고 있는지 (양수 음수 O)
- 특정 사용자 u에 대해 $p_u$ 의 각 원소는 해당 factor 가 강한 아이템에 대해 사용자가 얼마나 관심을 가지는지 (양수 음수 O) <br> <br>
두 벡터의 내적 $q_i^{T} p_u$ 은 사용자 u와 아이템 i 사이의 interaction, 즉 아이템 특성 전반에 대한 사용자의 전체적인 선호도를 나타냅니다.   

사용자 u가 아이템 i에 부여할 평점 $r_{ui}$을 근사하는 예측값을 

$\hat{r}_{ui}$ 라 하며, 

식으로 표현하면 $\hat{r}_{ui} = q_i^{T} p_u$  입니다. <br>

### 🐾 SVD와의 관계
행렬 분해하니 SVD (Singular Value Decomposition, 특이값 분해)가 생각나지 않을 수가 없습니다. <br>
CF에 SVD를 적용하려면 user-item 평점 행렬을 분해해야하는데 평점 행렬은 대부분 값이 비어있는 희소 행렬이기 때문에 SVD를 쓰면 문제 (과적합 등..)가 발생합니다. <br>

### 🐾 결측치 처리와 정규화
Sparsity 문제를 해결하기 위해 예전에는 누락된 부분의 rating을 채워 넣어서 행렬을 더 Dense하게 만들었다고 합니다. <br>
그러나 이 방법은 데이터 양을 크게 증가시켜 계산 비용이 엄청 커지고, 혹시 잘못된 값으로 채운 다면 데이터를 왜곡시킬 수 있습니다. <br>
그래서 최근 연구들은 <span style="background-color: #fff3cd">누락값을 채우지 않고 관측된 평점만을 직접 모델링 하면서, 정규화(regularization)를 통해 과적합을 방지하는 방법</span>을 제안하였습니다. <br>
factor vector $p_u$와 $q_i$를 학습하기 위해 다음을 수행합니다. <br>

$\min_{q^*,\, p^*} \sum_{(u,i)\in K} \left( r_{ui} - q_i^\top p_u \right)^2 + \lambda \left( \lVert q_i \rVert^2 + \lVert p_u \rVert^2 \right)$

- λ : 정규화 상수, 시스템은 과거에 관측된 평점에 맞도록 모델을 학습하지만, 궁극적인 목표는 미래의 보지 못한 평점까지 잘 예측하는 것이기 때문에 학습된 파라미터의 크기에 패널티를 주는 정규화를 통해 과적합을 방지해야합니다. 보통은 cross validation 사용.<br>
- K : $r_ui$가 실제로 관측된 user-item 쌍 (훈련 데이터 집합)<br>
앞으로 아래에서 위의 식을 (2)번 식이라고 하겠습니다. 


## 5. Learning Algorithms
위의 (2)번 식을 최소화하기 위한 두가지 방법이 소개되었습니다. 

### 🐾 Stochastic gradient descent (확률적 경사하강법)
각 학습 사례에 대해 시스템은 평점 $r_{ui}$를 예측하고 다음과 같은 예측 오차를 계산합니다. <br>
$e_{ui} = r_{ui} - q_i^\top p_u$

그 후, 기울기(gradient)의 반대 방향으로, 크기 $\gamma$에 비례하는 양만큼 파라미터를 수정합니다.  <br>

- $q_i \leftarrow q_i + \gamma \cdot (e_{ui} p_u - \lambda q_i)$
- $p_u \leftarrow p_u + \gamma \cdot (e_{ui} q_i - \lambda p_u)$

이 방법은 구현이 쉽고 비교적 빠르게 동작하기 때문에 널리 사용되지만, 경우에 따라서는 ALS 최적화가 더 유리할 수 있다고 합니다. 

### 🐾 ALS (Alternating least squares)
$q_i$와 $p_u$가 모두 미지수이기 때문에 한 번에 같이 최적화하려고 하면 convex 하지 않아서 해를 바로 구하기 어렵습니다. <br>
그래서 ALS는 $q_i$를 고정한 상태에서 $p_u$를 계산하고, 다시 $p_u$를 고정한 상태에서 $q_i$를 계산하는 과정을 번갈아 수행합니다. 이를 (2)번 식의 값이 수렴할 때까지 반복합니다.  <br>
즉, <span style="background-color: #fff3cd">먼저 $q_i$(아이템 특성)는 고정했다고 치고 사용자 벡터 $p_u$만 계산한뒤, ,<br>
그 다음엔 반대로 $p_u$를 고정하고 → $q_i$를 다시 계산하는 것을 반복합니다. </span> <br>
(사용자 맞추고,, 아이템 맞추고...사용자 맞추고,.,,반복)<br>
이 과정을 계속 반복하면 예측 오차(식 2)가 점점 줄어들다가 어느 순간 거의 변하지 않게 되고, 그 상태를 “수렴했다”고 보는 것입니다. <br><br>
일반적으로 확률적 경사 하강법이 ALS보다 더 쉽고 빠르지만, 적어도 다음 두 가지 상황에서는 ALS가 더 유리하다고합니다. <br> <br>
1. 병렬화가 가능한 경우 <br>
  ALS에서는 각 사용자 벡터 $p_u$를 서로 독립적으로 계산할 수 있고,<br>각 아이템 벡터 $q_i$도 서로 독립적으로 계산할 수 있습니다. <br>즉 컴퓨터 여러 대(또는 GPU 여러 코어)가 동시에 나눠서 계산할 수 있기에 (=병렬화가 가능하다) 데이터가 클수록 ALS가 더 강해집니다. 

2.  암묵적 피드백(implicit data)을 사용하는 시스템인 경우 <br>
   현실에서는 클릭했는지, 시청했는지,오래봤는지, 검색했는지 등과 같은 implicit data가 rating 데이터보다 훨씬 많습니다. <br> rating과 달리 이는 거의 모든 사용자–아이템 쌍에 정보가 있어서 데이터가 희소하지 않습니다. <br>이 경우 SGD는 모든 데이터를 하나씩 순회해야 하므로 매우 느려지는데, ALS는 행렬 연산으로 한 번에 처리할 수 있어 훨씬 효율적입니다. 

> 요약하자면, <br>
> **SGD** : 작은/희소 평점 데이터에 강함
> **ALS** : 대규모 implicit feedback와 병렬 처리 환경에서 강함


## 6. Adding Biases
CF에서 어떤 사용자는 전반적으로 높은 평점을 주는 경향이 있을 수 있고, 어떤 아이템은 다른 아이템보다 평균적으로 높은 평점을 받을 수 있습니다.  실제로 어떤 상품은 다른 상품보다 널리 더 좋게(혹은 나쁘게) 인식되기도 합니다.
<br>
따라서 평점을 단순히 $q_i^\top p_u$ 형태의 상호작용만으로 설명하는 것은 적절하지 않습니다. <br>대신, 시스템은 사용자 또는 아이템 편향이 설명할 수 있는 부분을 먼저 분리하고, 실제 상호작용 부분만을 요인 모델링으로 설명합니다.  <br>
평점 $r_{ui}$에 대한 1차 근사 편향 모델은 다음과 같습니다: <br>

$b_{ui} = \mu + b_i + b_u$

<br>

-  $b_{ui}$ : 평점 $r_{ui}$에 포함된 편향 <br>
-  $\mu$ : 전체 평균 평점
-  $b_u$ : 사용자가 평균으로부터 얼마나 벗어났는지 (편차)
-  $b_i$ : 아이템이 평균으로부터 얼마나 벗어나는지 (편차)  

<br>
<br>

예를 들어 여민이가 영화 "타이타닉"에 줄 평점을 추정한다고 할 때, <br>
전체 평균 평점이 $\mu = 3.7$점이고, 타이타닉은 평균보다 0.5점 정도 높게 평가되는 영화라면 $b_i = 0.5$입니다. <br>
반면 Joe는 비판적인 사용자로 평균보다 0.3점 낮게 주는 경향이 있어 $b_u = -0.3$입니다. <br>
이러한 편향을 포함하면 식은 다음과 같이 확장됩니다. <br>

$\hat{r}_{ui} = \mu + b_i + b_u + q_i^\top p_u$

<br>

또, 이때 관측된 평점은 네 가지 요소(전체 평균, 아이템 편향, 사용자 편향, 사용자-아이템 상호작용)로 분해되어 각 구성요소가 자신이 설명해야 할 정보만 담당하게 됩니다. <br> 시스템은 다음의 제곱 오차 최소화를 통해 파라미터를 학습합니다. <br>

$\min_{p^*, q^*, b^*} \sum_{(u,i)\in K} 
\left(r_{ui} - \mu - b_u - b_i - p_u^\top q_i\right)^2 + \lambda \left(\|p_u\|^2 + \|q_i\|^2 + b_u^2 + b_i^2\right)$

편향(bias)는 관측된 신호의 많은 부분을 설명하기 때문에 이를 정확하게 모델링하는 것이 매우 중요하다고 합니다. 


## 7. Additional Input Sources
추천시스템은 종종 <span style="color: blue">**콜드 스타트 문제(cold start problem)**</span>가 있습니다. (이전 논문 정리글 참고)<br>
논문에서는 이를 완화하는 방법으로 써 추가적인 정보(Additional Input Sources)를 활용하는 것을 소개합니다. <br>
예를 들어 사용자가 직접 평점을 남기지 않더라도, 구매 기록이나 검색 기록과 같은 **암묵적 피드백(implicit feedback)**을 통해 사용자의 선호도를 추론할 수 있습니다. <br> <br>

### 🐾 implicit feedback 활용
Boolean 형태의 implicit feedback이 있다고 가정을 하고, $N(u)$는 사용자 $u$가 선호를 보인 아이템 집합을 의미할 때, <br>
각 아이템 $i$는 요인 벡터 $x_i \in \mathbb{R}^f$와 연결되어 사용자 u는 다음과 같은 벡터로 나타낼 수 있습니다. <br> <br>

$\sum_{i \in N(u)} x_i$

이는 사용자가 좋아한 item들의 factor vector를 모두 더한 것입니다. <br>


$|N(u)|^{-0.5} \sum_{i \in N(u)} x_i$

사용자가 어떤 item을 많이 소비했다고해서 벡터 크기가 과도하게 커질 경우 <span style="color: blue"> normalization </span>을 히면 도움이 되며, 위는 정규화 수식의 한 예시입니다. <br> <br><br>

### 🐾 사용자 속성정보 활용
이미 알고 있는 user의 성별, 연령대, 지역, 소득 수준 등과 같은 정보를 활용하는 방법입니다. <br>
<br>

사용자 u가 가진 속성 집합을 A(u)라고 할때, <br>
각 속성 a는 factor vector $y_a \in \mathbb{R}^f$로 표현됩니다. <br>
그럼 사용자 표현은 다음과 같이 확장될 수 있습니다. <br>

$\sum_{a \in A(u)} y_a$

### 🐾 모든 신호를 통합한 확장 모델


$\hat{r}_{ui}=\mu + b_u + b_i+q_i^\top\left[p_u+|N(u)|^{-0.5}\sum_{i \in N(u)} x_i+\sum_{a \in A(u)} y_a\right]$


- $\mu$ : 전체 평균
- $b_u$, $b_i$ : 사용자 및 아이템 편향
- $p_u$ : 기본 사용자 취향 벡터
- $\sum x_i$ : 암묵적 행동 기반 취향
- $\sum y_a$ : 사용자 속성 기반 정보

사용자를 단순히 rating만을 기반으로한 벡터가 아니라 implicit data와 인구통계 정보까지 포함한 확장된 벡터로 만드는 것입니다.


## 8. Temporal Dynamics



## 9. Inputs with Varying Confidence Levels

## 쫑알 쫑알
앞부분에서 짧게 말했던 게놈 프로젝트.. <br>
고등학교 1학년 때인지 2학년 때인지 세본이라는 친구가 학종을 위한 프로젝트를 같이 하자고 하면서 언급했던 건데.. <br> 저는 그때 당시 정말 1도 모르는 상태였기에 .. 그게 머란 하고 흐지부지 되었었는데 걔는 어떻게 이런걸 알고 있었던 것일까요..?? <br> 심지어 컴공도 아니고 메디컬을 희망하던 친구인ㄷ..?<br> 저도 요런 상식? 잡지식?이 풍부했으면 좋겠네요